# ğŸ“„ Payslip Intelligence Suite

An AI-powered on-premises microservice for processing payslips and financial documents with advanced fraud detection and verification capabilities.

## ğŸš€ Quick Start (Virtual Environment Setup)

This project uses a virtual environment to keep your Mac clean and avoid polluting your system Python installation.

### 1. Initial Setup

```bash
# Clone the repository (if not already done)
# cd income-verification

# Create virtual environment and install dependencies
make dev-setup

# Run interactive configuration wizard
make setup
```

### 2. Usage

```bash
# Process documents
make run

# Check system status
make status

# Validate configuration
make validate

# Run tests
make test
```

### 3. Manual Virtual Environment Activation (Optional)

If you prefer to work directly with the virtual environment:

```bash
# Show activation command
make activate

# Activate virtual environment manually
source ./venv/bin/activate

# Now you can use python/pip directly
python main.py ingest
python main.py status

# Deactivate when done
deactivate
```

## ğŸ“ Project Structure

```
income-verification/
â”œâ”€â”€ main.py                 # CLI entry point
â”œâ”€â”€ config.toml            # Configuration file
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ Makefile              # Build and development commands
â”œâ”€â”€ venv/                 # Virtual environment (auto-created)
â”œâ”€â”€ services/             # Core service modules
â”‚   â”œâ”€â”€ config.py         # Configuration management
â”‚   â”œâ”€â”€ models.py         # Data models
â”‚   â”œâ”€â”€ document_loader.py # File processing
â”‚   â”œâ”€â”€ extractor.py      # AI-powered extraction
â”‚   â”œâ”€â”€ ai_client.py      # AI provider abstraction
â”‚   â”œâ”€â”€ verifier.py       # Document verification
â”‚   â”œâ”€â”€ fraud_detector.py # Fraud detection
â”‚   â””â”€â”€ processor.py      # Main orchestrator
â”œâ”€â”€ tests/                # Comprehensive test suite
â”œâ”€â”€ .secrets/             # API keys (create this)
â”œâ”€â”€ incoming_docs/        # Documents to process (auto-created)
â”œâ”€â”€ archive/              # Processed documents (auto-created)
â””â”€â”€ output/               # Analysis results (auto-created)
```

## ğŸ”§ Available Make Commands

### Setup & Installation

- `make venv` - Create virtual environment
- `make install` - Install dependencies in venv
- `make dev-setup` - Complete development environment setup
- `make setup` - Interactive configuration wizard
- `make activate` - Show venv activation command

### Development

- `make test` - Run tests with coverage
- `make lint` - Code linting
- `make format` - Code formatting with Black
- `make typecheck` - Type checking with MyPy
- `make check` - All quality checks

### Execution

- `make run` - Process documents
- `make status` - System status
- `make validate` - Validate configuration

### Maintenance

- `make clean` - Clean temporary files
- `make clean-all` - Clean everything including venv
- `make requirements` - Update requirements.txt

## ğŸ› ï¸ Configuration

### 1. API Key Setup

The system supports both OpenAI and Anthropic providers:

```bash
# For OpenAI (default)
echo "your-openai-api-key-here" > .secrets/openai_key

# For Anthropic (alternative)
echo "your-anthropic-api-key-here" > .secrets/anthropic_key
```

### 2. Configuration File

Edit `config.toml` to customize:

```toml
[ai]
provider = "openai"                   # or "anthropic"
model = "gpt-4.1-mini"                # or "claude-sonnet-4-20250514"
api_key_file = ".secrets/openai_key"  # or .secrets/anthropic_key

[processing]
docs_folder = "incoming_docs"
archive_folder = "archive"
max_file_size_mb = 50
supported_formats = ["pdf", "png", "jpg", "jpeg"]

[verification]
max_age_months = 6
min_consecutive_periods = 3
require_qualified_accountant_signature = true

[fraud_detection]
confidence_threshold = 0.7
font_consistency_check = true
total_validation = true
ocr_quality_threshold = 0.8
```

## ğŸ“„ Document Processing Pipeline

### **How Document Processing Works**

The system uses a sophisticated dual-extraction approach to analyze financial documents:

#### **1. PDF to Image Conversion (Not Direct Upload)**
```
PDF Input â†’ [pdf2image + poppler] â†’ High-resolution PNG (200 DPI) â†’ Base64 encoding â†’ AI Vision API
```

**Why convert to image?**
- **AI Model Compatibility**: OpenAI GPT-4 Vision and Anthropic Claude only accept images (PNG, JPEG, WebP, GIF) - **not PDF files**
- **Visual Fraud Detection**: Captures formatting, layout, fonts, and visual elements that text extraction misses
- **Comprehensive Analysis**: Enables detection of visual tampering that pure text analysis cannot catch

#### **2. Dual Extraction Strategy**
```
PDF Input â†’ [Text Extraction via PyPDF2] + [Image Conversion via pdf2image] â†’ Combined AI Analysis
```

**Text Path**: Extracts structured data and readable content
**Visual Path**: Captures visual authenticity and formatting
**Combined**: Both sent to AI for comprehensive fraud detection

#### **3. AI Analysis Process**
The AI receives a multi-modal payload:
```json
{
  "role": "user", 
  "content": [
    {"type": "text", "text": "Financial document analysis prompt..."},
    {"type": "text", "text": "Extracted text: [PyPDF2 output]"},
    {"type": "image_url", "url": "data:image/png;base64,[visual content]"}
  ]
}
```

#### **4. Cost Structure**
- **Input tokens** (~2,880): Image + text + analysis prompt
- **Output tokens** (~391): Structured JSON response
- **Total cost**: ~$0.0007 per document (using gpt-4o-mini)
- **Efficiency**: Enterprise-grade analysis for less than $0.001 per document

## ğŸ” Fraud Detection System

### **Multi-Layer Fraud Detection Architecture**

#### **Layer 1: AI-Based Visual Analysis**
The AI vision model analyzes both visual and textual content for:
- **Font inconsistencies** (different fonts mixed in same document)
- **Layout anomalies** (misaligned text, irregular spacing)
- **Visual artifacts** (signs of digital manipulation)
- **Calculation errors** (totals don't match line items)
- **Document quality** (poor scans, re-scanning artifacts)

#### **Layer 2: Heuristic Text Validation**
Post-AI processing performs targeted checks:

**Text Pattern Analysis:**
```python
suspicious_patterns = {
    'altered_fonts': [r'[A-Za-z]+\d+[A-Za-z]+'],  # Mixed alphanumeric
    'formatting_issues': [r'\s{3,}'],             # Excessive whitespace
    'ocr_errors': ['|||', '###', 'l1l']           # Common OCR artifacts
}
```

**Mathematical Validation:**
- Income items vs declared totals (tolerance: 2p)
- Unrealistic amounts (flags >Â£50k per period)
- Negative amount detection

**Date Logic Validation:**
- Future date detection
- Logical ordering (start < end < pay date)
- Age validation (configurable threshold)

#### **Layer 3: Employer & Identity Verification**

**Employer Legitimacy:**
- Company suffix validation (Ltd, PLC, LLP, etc.)
- Suspicious name patterns (cash, temp, agency, etc.)
- Single-word employer detection

**NI Number Validation:**
- Format validation: `[A-Z]{2}\d{6}[A-Z]`
- Fake number detection: `AA000000A`, `XX123456X`, etc.

#### **Layer 4: Cross-Document Analysis**
When processing multiple documents:
- **Template reuse detection** using text similarity algorithms
- **Income consistency analysis** (identifies outliers >20% deviation)
- **Consecutive period validation** ensuring proper sequence

### **Why Image Analysis is Superior to Direct PDF Processing**

#### **Visual Fraud Techniques Detected:**
1. **Font Substitution**: Changing numbers using slightly different fonts
2. **Digital White-out**: Covering original text with white boxes
3. **Copy-paste Tampering**: Combining elements from multiple documents
4. **Re-scanning Artifacts**: Evidence of print-and-scan to hide digital edits
5. **Layout Inconsistencies**: Misaligned elements indicating manual editing

#### **Real-World Example:**
A fraudster changes "Â£1,200" to "Â£12,000":
- **Text extraction** shows: "Â£12,000" (the altered text)
- **Image analysis** detects: Font inconsistency, alignment issues, visual artifacts

#### **Alternative Approaches Considered:**

**âŒ Pure Text Extraction:**
- Misses visual tampering
- Can't detect font inconsistencies
- Vulnerable to sophisticated PDF editing

**âŒ PDF Structure Analysis:**
- AI models don't support PDF parsing natively
- Complex implementation required
- Still misses visual fraud indicators

**âœ… Hybrid OCR + Vision (Current Approach):**
- Leverages standard AI vision APIs
- Detects both textual and visual fraud
- Comprehensive verification of content and authenticity
- Cost-effective using existing AI infrastructure

## ğŸ” Features

### Document Processing

- âœ… Multi-format support (PDF, PNG, JPG, JPEG)
- âœ… Automatic deduplication
- âœ… OCR quality assessment
- âœ… Batch processing with progress tracking
- âœ… Date-based archiving

### AI-Powered Analysis

- âœ… Document classification (payslip, bank statement, other)
- âœ… Structured data extraction
- âœ… Employee and employer information
- âœ… Income categorization (salary, bonus, commission, benefits)
- âœ… Confidence scoring per field

### Verification Engine

- âœ… Document recency validation
- âœ… Consecutive period checking
- âœ… Qualified accountant signature verification
- âœ… Mathematical consistency validation

### Fraud Detection

- âœ… Text consistency analysis
- âœ… Font inconsistency detection
- âœ… Calculation validation
- âœ… Employer legitimacy checks
- âœ… Date pattern anomalies
- âœ… NI number format validation
- âœ… Template reuse detection

## ğŸ“Š Output Format

Results are saved as JSON files with this structure:

```json
{
  "document_type": "payslip",
  "employee": {
    "name": "John Smith",
    "ni_number": "AB123456C",
    "confidence": 0.95
  },
  "employer": {
    "name": "Acme Corporation Ltd",
    "confidence": 0.9
  },
  "income": [
    {
      "type": "salary",
      "amount_gbp": 3000.0,
      "confidence": 0.95
    }
  ],
  "verifications": {
    "recency_pass": true,
    "consecutive_pass": true,
    "total_consistency_pass": true
  },
  "fraud_signals": [],
  "overall_confidence": 0.92
}
```

## ğŸ§ª Testing

The project includes comprehensive test coverage:

```bash
# Run all tests
make test

# Run specific test file
source ./venv/bin/activate
pytest tests/test_extractor.py -v

# Run with coverage report
make test
# Open htmlcov/index.html for detailed coverage
```

## ğŸ”’ Security

- âœ… API keys stored outside source control
- âœ… No secrets in logs or output
- âœ… Secure file handling
- âœ… Input validation and sanitization
- âœ… Virtual environment isolation

## ğŸ› Troubleshooting

### Virtual Environment Issues

```bash
# If venv gets corrupted, rebuild it
make clean-all
make dev-setup
```

### Missing Dependencies

```bash
# Reinstall all dependencies
make install
```

### Permission Issues

```bash
# Ensure proper permissions on secrets
chmod 600 .secrets/*
```

### API Key Issues

```bash
# Validate your configuration
make validate
```

## ğŸ“ Development

### Adding New Features

1. Create feature branch
2. Add code in appropriate service module
3. Add comprehensive tests
4. Run quality checks: `make check`
5. Update documentation

### Code Style

- Black formatting (100 char line length)
- Flake8 linting
- MyPy type checking
- Comprehensive docstrings

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch: `git checkout -b feature-name`
3. Set up development environment: `make dev-setup`
4. Make changes and add tests
5. Run quality checks: `make check`
6. Commit and push changes
7. Create pull request

## ğŸ“„ License

This project is designed for defensive security use only. Commercial use requires appropriate licensing.

---

**Note**: This system uses virtual environments to keep your Mac clean. All Python dependencies are installed in `./venv/` and won't affect your system Python installation.
